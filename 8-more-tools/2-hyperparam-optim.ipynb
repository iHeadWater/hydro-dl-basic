{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 超参数优化\n",
    "\n",
    "神经网络的设计和训练仍然是具有挑战性和不可预测的过程。根据研究人员的知识和经验，调整这些模型的难度使训练和复现结果更像一门艺术而不是科学。造成这种困难的原因之一是机器学习模型的训练过程包括多个超参数，这些参数会影响模型在训练过程中如何拟合数据。这些超参数直接控制训练算法的行为，并对所得机器学习模型的性能产生重大影响。与内部模型参数不同（例如神经网络的权重，可以在模型训练阶段从数据中学习），超参数要在学习过程之前进行设置。\n",
    "\n",
    "用于超参数优化的最广泛使用的方法是手动调整，这需要专业知识和专家经验。但是，在许多情况下，训练神经网络的经验还不够，研究人员诉诸于蛮力的网格搜索。此外，依靠过去的经验通常提供的是可行的方法，而不是最佳的超参数集。为了降低普通用户的技术门槛，近年来自动超参数优化已成为热门话题。\n",
    "\n",
    "本文就简单记录下 Optuna -- 一个超参数优化框架，实现操作简单，准确，快速的超参数优化。\n",
    "\n",
    "## 超参数优化挑战\n",
    "\n",
    "传统上，超参数优化一直是人类的工作，因为它们在只能进行少量试验的方案中非常有效。如果您有一组具有丰富经验的研究人员在高度相似的数据上使用相同的模型，则这种手动优化方法有时称为“the graduate student search”或简称为“babysitting”，在计算效率上被认为是有效的。即使这样，它主要还是在要调整的超参数数量很少的情况下才是合理的。但是，它自然依赖于训练有素的体力劳动，可以达到可行但并非最佳的效果。此外，这是一个串行过程，因为这是一个反复试验的过程，研究人员需要从先前的试验中学习并调整后续试验的参数。在计算机集群和GPU处理器可以并行运行大量试验的世界中，人为操作可能会成为优化过程的瓶颈。因此，自动超参数优化领域开始引起机器学习社区的关注。在介绍一些最流行，最有效的自动优化技术之前，需要注意的是，相关人员的讨论可以使研究人员对要优化的超参数有一定程度的了解。这种洞察力对于研究人员不断改进模型和训练算法的能力至关重要。因此这一工作中的人应该在任何自动化过程中都保持一定了解，并确保优化过程对数据科学家可见。\n",
    "\n",
    "近年来，几种自动优化方法变得越来越流行。最受欢迎的是：\n",
    "\n",
    "- 网格搜索-在网格搜索中，我们为每个参数选择一组值，然后通过组合值的每种可能组合来形成一组试验。它实现起来简单，并行化也很简单。但是，由于值的数量随超参数的数量呈指数增长，因此它遭受了维数灾。\n",
    "- 随机搜寻 —随机搜索被认为是网格搜索的一种变体，可以在相同的配置空间中从均匀密度中独立地绘制随机值，就像网格搜索所跨越的那样。随机搜索具有网格搜索的所有实用优势（简单，易于实现，琐碎的并行性），并在低维空间中以较小的效率降低为代价，而在高维搜索空间中以较大的幅度提高效率。在高维空间中，它比网格搜索更有效，因为我们旨在优化的超参数函数对某些维的变化比其他维更敏感。这使随机搜索成为与更高级的超参数优化算法进行比较的基准。\n",
    "- 贝叶斯优化—贝叶斯优化框架具有几个关键要素。主要成分是概率替代模型，它由一个先验分布组成，该分布捕获了我们对未知目标函数的行为的信念。它还包括一个描述数据生成机制的观察模型。观察到目标的每个查询的输出后，更新先验以在目标函数的空间上产生更具信息量的后验分布。为了获得更高的效率，贝叶斯优化使用采集函数来权衡勘探和开发；他们的最优值位于代理模型的不确定性较大（探索）和/或模型预测较高的位置（探索）。贝叶斯优化算法然后通过最大化此类获取函数来选择下一个查询点。尽管贝叶斯优化的性能优于网格搜索和随机搜索，但以其形式，它有两个主要缺点：它不是并行算法，并且仅适用于连续的超参数，而不适用于分类的超参数。对于这两个问题，近年来已经开发出贝叶斯优化的几种变体。\n",
    "- 超频带优化—尽管贝叶斯优化的目标是通过自适应方式选择超参数配置，以使其比标准基线（例如随机搜索）更高效，更快，但它需要解决从根本上挑战性的问题，即同步拟合和优化高维，非具有未知平滑度的凸函数，并且可能包含嘈杂的评估。超频带是一种通用技术，它通过做出最少的假设来避免此问题，并专注于解决如何在随机采样的超参数配置之间分配资源。Hyperband本质上是随机搜索的一种变体，它使用原则上的提前停止策略和SuccessiveHalving算法的扩展来分配资源。因此，在给定资源预算的情况下，Hyperband可以评估更多的超参数配置，并且在各种深度学习问题上的收敛速度都比贝叶斯优化快。\n",
    "\n",
    "自动优化技术一直在不断发展，每两个月发布一次更新和改进的算法。可以探索这些较新的算法，例如结合了Hyperband算法和贝叶斯优化的[BOHB](https://arxiv.org/pdf/1807.01774.pdf)（贝叶斯优化和HyperBand），以及融合了遗传优化算法的思想的[PBT](https://arxiv.org/pdf/1711.09846.pdf)（Population-Based Training），等等。\n",
    "\n",
    "下面就在PyTorch生态系统下利用Optuna尝试自动执行超参数搜索。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optuna: A hyperparameter optimization framework\n",
    "\n",
    "Optuna 是一个开源自动超参数优化框架，专门为机器学习而设计。得益于其模块化的设计和现代优化功能的使用，它拥有一种轻量级的体系结构，该体系结构支持并行分布式优化以及对毫无希望的试验的修剪。\n",
    "\n",
    "先定义俩名词：\n",
    "\n",
    "- Study: optimization based on an objective function\n",
    "- Trial: a single execution of the objective function\n",
    "\n",
    "study的目标是通过多次trials找到超参数的最优解。Optuna 就是studies加速和自动化的框架。\n",
    "\n",
    "首先，通过官方文档下的[视频](https://optuna.readthedocs.io/en/stable/tutorial/index.html)了解 Optuna的基本框架，了解其中的基本算法，初步了解一般对算法的选择，这里挑出一些重点简单记录下。\n",
    "\n",
    "常用的算法有：\n",
    "\n",
    "- Model-based:\n",
    "    - TPE:bayesian optimization based on kernel fitting\n",
    "    - GP:bayesian optimization based on Gaussian processes\n",
    "    - CMA-ES:meta-heuristics algorithm for continuous space\n",
    "- Other Methods:\n",
    "    - Random search\n",
    "    - Grid search\n",
    "    - User-defined algorithm\n",
    "    \n",
    "选择的大致情况如下图：\n",
    "\n",
    "![](pictures/QQ截图20210415162051.png)\n",
    "\n",
    "默认的算法是TPE，如果不知道选择哪个，默认的就行了。\n",
    "\n",
    "Optuna中设置了 Pruning strategy，如下图所示。\n",
    "\n",
    "![](pictures/QQ截图20210415162405.png)\n",
    "\n",
    "优化会基于学习曲线提前停止那些明显不行的trials。\n",
    "\n",
    "Optuna的可视化也不错；此外，能识别出来哪些超参数更值得调整 -- Hyperparameter Importances。\n",
    "\n",
    "Optuna基本使用代码模板如下图：\n",
    "\n",
    "![](pictures/QQ截图20210415162902.png)\n",
    "\n",
    "下面是一个简单的例子，来自：https://github.com/optuna/optuna/blob/master/examples/pytorch/pytorch_simple.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "import optuna\n",
    "from optuna.trial import TrialState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cpu\")\n",
    "BATCHSIZE = 128\n",
    "CLASSES = 10\n",
    "DIR = os.getcwd()\n",
    "EPOCHS = 10\n",
    "LOG_INTERVAL = 10\n",
    "N_TRAIN_EXAMPLES = BATCHSIZE * 30\n",
    "N_VALID_EXAMPLES = BATCHSIZE * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnist():\n",
    "    # Load FashionMNIST dataset.\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.FashionMNIST(DIR, train=True, download=True, transform=transforms.ToTensor()),\n",
    "        batch_size=BATCHSIZE,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        datasets.FashionMNIST(DIR, train=False, transform=transforms.ToTensor()),\n",
    "        batch_size=BATCHSIZE,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(trial):\n",
    "    # We optimize the number of layers, hidden units and dropout ratio in each layer.\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
    "    layers = []\n",
    "\n",
    "    in_features = 28 * 28\n",
    "    for i in range(n_layers):\n",
    "        out_features = trial.suggest_int(\"n_units_l{}\".format(i), 4, 128)\n",
    "        layers.append(nn.Linear(in_features, out_features))\n",
    "        layers.append(nn.ReLU())\n",
    "        p = trial.suggest_float(\"dropout_l{}\".format(i), 0.2, 0.5)\n",
    "        layers.append(nn.Dropout(p))\n",
    "\n",
    "        in_features = out_features\n",
    "    layers.append(nn.Linear(in_features, CLASSES))\n",
    "    layers.append(nn.LogSoftmax(dim=1))\n",
    "\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后是目标："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    # Generate the model.\n",
    "    model = define_model(trial).to(DEVICE)\n",
    "\n",
    "    # Generate the optimizers.\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "\n",
    "    # Get the FashionMNIST dataset.\n",
    "    train_loader, valid_loader = get_mnist()\n",
    "\n",
    "    # Training of the model.\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            # Limiting training data for faster epochs.\n",
    "            if batch_idx * BATCHSIZE >= N_TRAIN_EXAMPLES:\n",
    "                break\n",
    "\n",
    "            data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation of the model.\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in enumerate(valid_loader):\n",
    "                # Limiting validation data.\n",
    "                if batch_idx * BATCHSIZE >= N_VALID_EXAMPLES:\n",
    "                    break\n",
    "                data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
    "                output = model(data)\n",
    "                # Get the index of the max log-probability.\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        accuracy = correct / min(len(valid_loader.dataset), N_VALID_EXAMPLES)\n",
    "\n",
    "        trial.report(accuracy, epoch)\n",
    "\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-04-15 16:36:43,351]\u001b[0m A new study created in memory with name: no-name-11c0a3bc-8495-43b9-85aa-360957996197\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to E:\\Code\\hydrus\\5-dl-tools\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c90846d60fa74a28ac171b8e6a10311e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting E:\\Code\\hydrus\\5-dl-tools\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to E:\\Code\\hydrus\\5-dl-tools\\FashionMNIST\\raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to E:\\Code\\hydrus\\5-dl-tools\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04333c16fb4a4058a675aa6c3941ec05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting E:\\Code\\hydrus\\5-dl-tools\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to E:\\Code\\hydrus\\5-dl-tools\\FashionMNIST\\raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to E:\\Code\\hydrus\\5-dl-tools\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f5970ee4dcc4daa934a631b42b32c20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting E:\\Code\\hydrus\\5-dl-tools\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to E:\\Code\\hydrus\\5-dl-tools\\FashionMNIST\\raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to E:\\Code\\hydrus\\5-dl-tools\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9b969ba577a4261bf2dde42cdf47cd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting E:\\Code\\hydrus\\5-dl-tools\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to E:\\Code\\hydrus\\5-dl-tools\\FashionMNIST\\raw\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11445\\miniconda3\\envs\\hydrus\\lib\\site-packages\\torchvision\\datasets\\mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:141.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11445\\miniconda3\\envs\\hydrus\\lib\\site-packages\\torch\\autograd\\__init__.py:132: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  ..\\c10\\cuda\\CUDAFunctions.cpp:100.)\n",
      "  allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[32m[I 2021-04-15 16:37:19,484]\u001b[0m Trial 0 finished with value: 0.4859375 and parameters: {'n_layers': 1, 'n_units_l0': 86, 'dropout_l0': 0.48429827183831015, 'optimizer': 'RMSprop', 'lr': 1.0373063346856026e-05}. Best is trial 0 with value: 0.4859375.\u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:37:26,052]\u001b[0m Trial 1 finished with value: 0.75390625 and parameters: {'n_layers': 1, 'n_units_l0': 119, 'dropout_l0': 0.43323830510373035, 'optimizer': 'Adam', 'lr': 0.00017623483743615243}. Best is trial 1 with value: 0.75390625.\u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:37:32,753]\u001b[0m Trial 2 finished with value: 0.484375 and parameters: {'n_layers': 1, 'n_units_l0': 127, 'dropout_l0': 0.41407066465543324, 'optimizer': 'RMSprop', 'lr': 0.0707901147835271}. Best is trial 1 with value: 0.75390625.\u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:37:39,287]\u001b[0m Trial 3 finished with value: 0.7515625 and parameters: {'n_layers': 1, 'n_units_l0': 25, 'dropout_l0': 0.33142247293983174, 'optimizer': 'Adam', 'lr': 0.0005044437980356456}. Best is trial 1 with value: 0.75390625.\u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:37:45,986]\u001b[0m Trial 4 finished with value: 0.75859375 and parameters: {'n_layers': 2, 'n_units_l0': 74, 'dropout_l0': 0.3650070725299732, 'n_units_l1': 62, 'dropout_l1': 0.3214941799178052, 'optimizer': 'RMSprop', 'lr': 0.0002985231693352127}. Best is trial 4 with value: 0.75859375.\u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:37:52,431]\u001b[0m Trial 5 finished with value: 0.76953125 and parameters: {'n_layers': 1, 'n_units_l0': 24, 'dropout_l0': 0.46042893376915744, 'optimizer': 'Adam', 'lr': 0.008173720934300854}. Best is trial 5 with value: 0.76953125.\u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:37:53,169]\u001b[0m Trial 6 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:37:53,881]\u001b[0m Trial 7 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:37:54,599]\u001b[0m Trial 8 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:38:01,303]\u001b[0m Trial 9 finished with value: 0.76640625 and parameters: {'n_layers': 1, 'n_units_l0': 105, 'dropout_l0': 0.371638057745929, 'optimizer': 'Adam', 'lr': 0.000249464299368042}. Best is trial 5 with value: 0.76953125.\u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:38:02,346]\u001b[0m Trial 10 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:38:03,060]\u001b[0m Trial 11 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-04-15 16:38:03,768]\u001b[0m Trial 12 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:38:04,483]\u001b[0m Trial 13 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:38:10,782]\u001b[0m Trial 14 finished with value: 0.778125 and parameters: {'n_layers': 1, 'n_units_l0': 32, 'dropout_l0': 0.45763240285159495, 'optimizer': 'Adam', 'lr': 0.016257768967406792}. Best is trial 14 with value: 0.778125.\u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:38:11,563]\u001b[0m Trial 15 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:38:12,941]\u001b[0m Trial 16 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:38:19,635]\u001b[0m Trial 17 finished with value: 0.79921875 and parameters: {'n_layers': 1, 'n_units_l0': 43, 'dropout_l0': 0.4277706541647851, 'optimizer': 'Adam', 'lr': 0.004923723025427377}. Best is trial 17 with value: 0.79921875.\u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:38:26,523]\u001b[0m Trial 18 finished with value: 0.803125 and parameters: {'n_layers': 2, 'n_units_l0': 55, 'dropout_l0': 0.4162865118908323, 'n_units_l1': 39, 'dropout_l1': 0.4129252734565883, 'optimizer': 'Adam', 'lr': 0.00377529672905905}. Best is trial 18 with value: 0.803125.\u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:38:27,340]\u001b[0m Trial 19 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:38:28,082]\u001b[0m Trial 20 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:38:35,339]\u001b[0m Trial 21 finished with value: 0.78125 and parameters: {'n_layers': 2, 'n_units_l0': 42, 'dropout_l0': 0.4373959672702797, 'n_units_l1': 102, 'dropout_l1': 0.47654055082023306, 'optimizer': 'Adam', 'lr': 0.003225425147993168}. Best is trial 18 with value: 0.803125.\u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:38:36,100]\u001b[0m Trial 22 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:38:36,874]\u001b[0m Trial 23 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:38:37,655]\u001b[0m Trial 24 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:38:38,335]\u001b[0m Trial 25 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:38:39,017]\u001b[0m Trial 26 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:38:39,743]\u001b[0m Trial 27 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:38:40,426]\u001b[0m Trial 28 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:38:47,019]\u001b[0m Trial 29 finished with value: 0.79375 and parameters: {'n_layers': 2, 'n_units_l0': 75, 'dropout_l0': 0.48070451821682825, 'n_units_l1': 114, 'dropout_l1': 0.46231730878897465, 'optimizer': 'RMSprop', 'lr': 0.0023902340908810407}. Best is trial 18 with value: 0.803125.\u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:38:53,774]\u001b[0m Trial 30 finished with value: 0.79296875 and parameters: {'n_layers': 2, 'n_units_l0': 86, 'dropout_l0': 0.47472163992751565, 'n_units_l1': 52, 'dropout_l1': 0.4057660871174905, 'optimizer': 'RMSprop', 'lr': 0.0016116666183320675}. Best is trial 18 with value: 0.803125.\u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:38:54,534]\u001b[0m Trial 31 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:38:55,250]\u001b[0m Trial 32 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:38:56,022]\u001b[0m Trial 33 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:38:59,463]\u001b[0m Trial 34 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:39:06,126]\u001b[0m Trial 35 finished with value: 0.7796875 and parameters: {'n_layers': 2, 'n_units_l0': 97, 'dropout_l0': 0.4685044595295222, 'n_units_l1': 118, 'dropout_l1': 0.38356809734744224, 'optimizer': 'RMSprop', 'lr': 0.0010691153712037815}. Best is trial 18 with value: 0.803125.\u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:39:06,764]\u001b[0m Trial 36 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:39:07,388]\u001b[0m Trial 37 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:39:08,066]\u001b[0m Trial 38 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:39:08,737]\u001b[0m Trial 39 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:39:09,409]\u001b[0m Trial 40 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:39:10,111]\u001b[0m Trial 41 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:39:16,554]\u001b[0m Trial 42 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:39:17,241]\u001b[0m Trial 43 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:39:18,000]\u001b[0m Trial 44 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:39:18,660]\u001b[0m Trial 45 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:39:19,366]\u001b[0m Trial 46 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:39:20,106]\u001b[0m Trial 47 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:39:20,810]\u001b[0m Trial 48 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:39:21,515]\u001b[0m Trial 49 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:39:22,242]\u001b[0m Trial 50 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:39:22,975]\u001b[0m Trial 51 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:39:23,720]\u001b[0m Trial 52 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:39:30,253]\u001b[0m Trial 53 finished with value: 0.81796875 and parameters: {'n_layers': 2, 'n_units_l0': 128, 'dropout_l0': 0.4879776714312115, 'n_units_l1': 127, 'dropout_l1': 0.4074273545109544, 'optimizer': 'RMSprop', 'lr': 0.0018722204406319567}. Best is trial 53 with value: 0.81796875.\u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:39:31,016]\u001b[0m Trial 54 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:39:31,766]\u001b[0m Trial 55 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:39:32,550]\u001b[0m Trial 56 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:39:33,351]\u001b[0m Trial 57 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:39:34,042]\u001b[0m Trial 58 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:39:34,753]\u001b[0m Trial 59 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:39:35,433]\u001b[0m Trial 60 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:39:36,159]\u001b[0m Trial 61 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:39:38,247]\u001b[0m Trial 62 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:39:45,936]\u001b[0m Trial 63 finished with value: 0.80390625 and parameters: {'n_layers': 2, 'n_units_l0': 93, 'dropout_l0': 0.4220004033600841, 'n_units_l1': 124, 'dropout_l1': 0.37450619117053885, 'optimizer': 'RMSprop', 'lr': 0.0011982104903368231}. Best is trial 53 with value: 0.81796875.\u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:39:46,758]\u001b[0m Trial 64 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:39:47,614]\u001b[0m Trial 65 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:39:48,421]\u001b[0m Trial 66 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:39:49,201]\u001b[0m Trial 67 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:39:49,969]\u001b[0m Trial 68 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:39:50,714]\u001b[0m Trial 69 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:39:51,453]\u001b[0m Trial 70 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:39:52,199]\u001b[0m Trial 71 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:39:52,999]\u001b[0m Trial 72 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:39:53,782]\u001b[0m Trial 73 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:39:54,630]\u001b[0m Trial 74 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:39:55,403]\u001b[0m Trial 75 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:39:56,148]\u001b[0m Trial 76 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:39:56,896]\u001b[0m Trial 77 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:39:57,714]\u001b[0m Trial 78 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:39:58,506]\u001b[0m Trial 79 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:39:59,129]\u001b[0m Trial 80 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:39:59,864]\u001b[0m Trial 81 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:40:06,864]\u001b[0m Trial 82 finished with value: 0.796875 and parameters: {'n_layers': 1, 'n_units_l0': 33, 'dropout_l0': 0.4196447786969604, 'optimizer': 'Adam', 'lr': 0.013069320020980062}. Best is trial 53 with value: 0.81796875.\u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:40:09,381]\u001b[0m Trial 83 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:40:10,150]\u001b[0m Trial 84 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:40:16,900]\u001b[0m Trial 85 finished with value: 0.809375 and parameters: {'n_layers': 1, 'n_units_l0': 52, 'dropout_l0': 0.42817787203282504, 'optimizer': 'Adam', 'lr': 0.011466516237575414}. Best is trial 53 with value: 0.81796875.\u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:40:23,291]\u001b[0m Trial 86 finished with value: 0.796875 and parameters: {'n_layers': 1, 'n_units_l0': 53, 'dropout_l0': 0.4132894826345881, 'optimizer': 'Adam', 'lr': 0.012158234371099428}. Best is trial 53 with value: 0.81796875.\u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:40:29,809]\u001b[0m Trial 87 finished with value: 0.81171875 and parameters: {'n_layers': 1, 'n_units_l0': 52, 'dropout_l0': 0.42730866779423343, 'optimizer': 'Adam', 'lr': 0.012402556455301066}. Best is trial 53 with value: 0.81796875.\u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:40:36,438]\u001b[0m Trial 88 finished with value: 0.815625 and parameters: {'n_layers': 1, 'n_units_l0': 51, 'dropout_l0': 0.42859646813500146, 'optimizer': 'Adam', 'lr': 0.011742905281317481}. Best is trial 53 with value: 0.81796875.\u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:40:37,215]\u001b[0m Trial 89 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:40:43,971]\u001b[0m Trial 90 finished with value: 0.80078125 and parameters: {'n_layers': 1, 'n_units_l0': 49, 'dropout_l0': 0.4175436981552804, 'optimizer': 'Adam', 'lr': 0.01779356738851029}. Best is trial 53 with value: 0.81796875.\u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:40:50,770]\u001b[0m Trial 91 finished with value: 0.8203125 and parameters: {'n_layers': 1, 'n_units_l0': 50, 'dropout_l0': 0.41270830442333095, 'optimizer': 'Adam', 'lr': 0.011406576723933382}. Best is trial 91 with value: 0.8203125.\u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:40:54,126]\u001b[0m Trial 92 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:40:54,887]\u001b[0m Trial 93 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:41:01,434]\u001b[0m Trial 94 finished with value: 0.8109375 and parameters: {'n_layers': 1, 'n_units_l0': 58, 'dropout_l0': 0.3868042299048528, 'optimizer': 'Adam', 'lr': 0.010785276627431664}. Best is trial 91 with value: 0.8203125.\u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:41:07,719]\u001b[0m Trial 95 finished with value: 0.8265625 and parameters: {'n_layers': 1, 'n_units_l0': 56, 'dropout_l0': 0.38846973810012325, 'optimizer': 'Adam', 'lr': 0.010659780884583012}. Best is trial 95 with value: 0.8265625.\u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:41:08,434]\u001b[0m Trial 96 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:41:15,095]\u001b[0m Trial 97 finished with value: 0.78828125 and parameters: {'n_layers': 1, 'n_units_l0': 56, 'dropout_l0': 0.38340956468002785, 'optimizer': 'Adam', 'lr': 0.01975515112291501}. Best is trial 95 with value: 0.8265625.\u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:41:21,558]\u001b[0m Trial 98 finished with value: 0.80703125 and parameters: {'n_layers': 1, 'n_units_l0': 62, 'dropout_l0': 0.3890108745178272, 'optimizer': 'Adam', 'lr': 0.008459588509415706}. Best is trial 95 with value: 0.8265625.\u001b[0m\n",
      "\u001b[32m[I 2021-04-15 16:41:28,385]\u001b[0m Trial 99 finished with value: 0.82109375 and parameters: {'n_layers': 1, 'n_units_l0': 63, 'dropout_l0': 0.38899236910234797, 'optimizer': 'Adam', 'lr': 0.009300352572692905}. Best is trial 95 with value: 0.8265625.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics: \n",
      "  Number of finished trials:  100\n",
      "  Number of pruned trials:  72\n",
      "  Number of complete trials:  28\n",
      "Best trial:\n",
      "  Value:  0.8265625\n",
      "  Params: \n",
      "    n_layers: 1\n",
      "    n_units_l0: 56\n",
      "    dropout_l0: 0.38846973810012325\n",
      "    optimizer: Adam\n",
      "    lr: 0.010659780884583012\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100, timeout=600)\n",
    "\n",
    "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上就是基本的用法。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
